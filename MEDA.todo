'Cmd/Ctrl+Enter' // Triggers `Todo: Toggle Box`
'Alt+Enter' // Triggers `Todo: Toggle Box`
'Alt+D' // Triggers `Todo: Toggle Done`
'Alt+C' // Triggers `Todo: Toggle Cancelled`
'Alt+S' // Triggers `Todo: Toggle Start`
'Cmd/Ctrl+Shift+A' // Triggers  `Todo: Archive`

# x = _info[3]['terminal_observation']

from stable_baselines import results_plotter
log_dir = "/home/elfar/MEDA/a_log/"
results_plotter.plot_results([log_dir], 1e5, results_plotter.X_TIMESTEPS, "MEDA")
plt.draw()
plt.savefig('a_log/_Plot.png')

LIST:
    0826a_030x030_E100_NPS64_00 use for 30x30
    ./data/0917a_060x030_E100__00 use for 60x30
        For future, stop at 12.9 cycles

MEDA.TODOLIST:
    ✔ Understand the learning process @done(21-08-23 15:49)
        ✔ Draw an outline of the learning @done(21-08-23 15:49)

    ✔ Ensure fair distribution of RJs @done(21-08-29 11:20)
        ✔ Create a variable at each reset @done(21-08-29 11:20)
        ✔ Monitor the distribution @done(21-08-29 11:20)
        ✔ Correct distribution accodingly @done(21-08-29 11:20)

    ☐ Implement and test bioassay scheduler
        ✔ Migrate args from test to test_bioassay @done(21-09-02 13:27)
        ✔ Test simple bioassay using trained agent @done(21-09-02 18:57)
        ✔ Implement separate routine for dispensing @done(21-09-02 18:57)
    
    ☐ Run bioassay experiments
        ☐ Transfer learning for 60x30


MEDA.RJ:
    ☐ Prepare documents
        ✔ PDF Entire manuscript @done(21-08-27 08:47)
        ✔ LATEX Manuscript Latex softcopy @done(21-08-27 08:47)
        ✔ PDF Figs + Tables with no captions @done(21-08-27 08:47)
        ✔ PDF List of all figure and table captions in proper style @done(21-08-27 08:47)
        ✔ Include Tung-Che biography @done(21-08-30 15:43)
        ✔ Include Krish's photo @done(21-08-30 17:47)
        ✔ Correct photo ratio @done(21-08-30 17:47)
        ☐ Update Krish's bio
        ☐ Update Miroslav's bio
        ☐ Send out to everyone with comments
        

        ☐ PDF of each figure separately
        ☐ Brief technical biography of each author + tiff photo

MEDA.NOTES:
    -- Increasing the number of minibatches was pivotal
    -- Manually add padding is to be examined
    -- Might need to consider a controlled random sampling of routing jobs
    -- Neither learn() nor evaluate() resets the environment...
        ✔ Reset the environment after each evaluation @done(21-08-20 09:00)
            Reaches 100 at 72 (compared to 33) but seems more stable
        ☐ Use a separate environment for evaluation

MEDA.MASTER:
    A. Verify results for other configurations:
        ☐ Verify for random routing jobs
            ✔ Randomize initial state @done(21-08-19 10:26)
            ✔ Obtain and examine results @done(21-08-19 10:26)
            ✔ Randomize goal state @done(21-08-19 10:26)
            ✔ Obtain and examine results @done(21-08-19 10:26)
        
        ☐ Verify for degradation modes
            ☐ Reuse pre-trained policy network
    
    B. Hyperparameter tuning:
        ☐ Change LR factor from 0.1 to 0.5


MEDA.PROBLEMS:
    Investigate Points discussed with Qitong:
         ☐ Verify that we use deterministic actions
         ☐ 

    Implement Learning Rate Scheduler:
        ✔ Check the schedules package @done(21-08-12 12:22)
        ✔ Implement decaying rate @done(21-08-12 12:22)
        
    Apply New Observation for Illegal Moves:
        ✔ Create flag variable @done(21-08-07 07:37)
        ✔ Reset flags in reset() @done(21-08-07 08:00)
        ✔ Set flags in updatePosition() @done(21-08-07 08:00)
        ☐ Add to observation in updatePosition()
    Wrapping Up:
        ☐ Run test 0729a
            15x15, nps=32, init=(3,3), end=(8,11)
    Steps for debugging:
        ✔ Examine the behavior of the bugs @done(21-07-26 21:49)
        ☐ Test with manhatten distance
    ☐ Final Testing
        ✔ Test a very small policy step @done(21-07-26 11:28)
            Fast convergence
        ☐ Test nps=16 and 30x30
    ✔ Investigate the weird behavior @done(21-07-26 11:15)
        ☐ Train network for 3 instead of 1,3 @started(21-07-25 07:13)
            Converges at around 40 epochs
        ☐ Train network on any range
        ☐ Check CNN configuration
            ✔ Is State set correctly? @done(21-07-25 08:34)
                Not needed, only for recurrent policies
            ✔ Do we need Deterministic? @done(21-07-26 07:08)
                Perhaps
        ✔ Test 15x15 @done(21-07-26 07:09)
            Same behavior
        ✔ Test normal reward structure @done(21-07-26 11:15)
        ✔ Increase penalty when stopping anywhere @done(21-07-26 11:15)
    ✔ Create an array of environments in scheduler @done(21-07-20 08:09)
    ✔ Assign to routing jobs @done(21-07-20 12:25)
        ✔ Create assignment list @done(21-07-20 08:15)
        ✔ Attach to RJ when ready @done(21-07-20 08:35)
        ✔ Release from RJ when done @done(21-07-20 12:24)
    ☐ Set ENV to RJ settings
        ✔ Initialize the enviornment at assignment @done(21-07-21 09:04)
        ✔ Create RJ transformation function @done(21-07-24 08:51)
    ☐ Make routing jobs self contained
    ☐ Create transformation function (from and to RJ)
    ☐ Store transformation parameters
    ☐ Test basic scheduler functionality
    ☐ Collect all required metrics

MEDA.PaperWriting:
    ☐ Update model action space

MEDA.Evaluation:
    ☐ MEDA Scheduler
        ☐ Impl. bioassays
            ✔ Copy bioassays to new file @started(21-07-03 07:54) @done(21-07-03 09:01) @lasted(1h8m)
            ☐ Convert to lists @started(21-07-03 10:47)
            ☐ Implement MO importer
    
    ☐ Prepare testing environment
        ☐ Implement set initial state
        ☐ Implement performance measure collector
        ☐ Implement case studies
        ☐ Transfer case studies to PRISM
        

MEDA.Coding:
    `Must finish this first and foremost!`
    ✔ @critical Finish major changes before pilot testing @started(21-05-25 21:59) @done(21-06-02 08:31) @lasted(1w10h32m33s)
        ✔ Randomize droplet size @started(21-05-25 20:13) @done(21-05-25 21:55) @lasted(1h42m35s)
        ✔ Apply padding using the hazard zone @started(21-05-25 21:56) @done(21-05-26 00:03) @lasted(2h7m3s)
            ✔ Remove the extra layer from observation @started(21-05-25 22:43) @done(21-05-26 00:02) @lasted(1h19m40s)
            ✔ Modify observation in _getObs() @started(21-05-25 22:43) @done(21-05-26 00:02) @lasted(1h19m22s)
            ✔ Modify observation in _getFrame() @started(21-05-25 22:43) @done(21-05-26 00:02) @lasted(1h19m27s)
            ✔ Pad observation @started(21-05-26 09:00) @done(21-05-26 15:15) @lasted(1d15m16s)
                You can either (a) override actions, (b) set degradation to 0
                I choose to merge both options by the following 
                    ✔ Create hazard limits @started(21-05-26 09:00) @done(21-05-26 09:33) @lasted(33m23s)
                    ✔ Update HL and step_max @started(21-05-26 09:30) @done(21-05-26 10:39) @lasted(1h9m50s)
                    ✔ Update observation @started(21-05-26 10:52) @done(21-05-26 10:59) @lasted(7m20s)
                    ✔ Use HL for actions @started(21-05-26 10:39) @done(21-05-26 14:12) @lasted(3h33m50s)
                    ✘ Show HL in frame @cancelled(21-05-26 14:13)

        ✔ Update the reward structure accordingly @done(21-06-02 08:31)

    ☐ Create a logging system for everything worth logging
        ☐ Make a list of things to log @started(21-05-27 13:22)
            ID, time(s), rewards, success rate, no. cycles
        ☐ Quick search how to implement
        ☐ Implement

    ✔ Implement random seed @done(21-05-25 21:37)
        ✔ Unify random everywhere @done(21-05-25 21:37)
        ✔ Add random seed options to args @done(21-05-25 21:37)

    ☐ @low Improve performance @started(21-05-27 10:37)
        ✔ Implement efficient eval func @started(21-05-27 10:37) @done(21-05-28 16:43) @lasted(1d6h6m30s)
        ☐ Replace np[:]=val with np[:].fill(val)

    ☐ @today Implement randomized degradation
        ✔ @high Implement _resetInitialHealth @started(21-06-01 18:38) @done(21-06-02 07:45) @lasted(13h7m49s)
            ✔ Implement normal mode @started(21-06-01 18:38) @done(21-06-01 18:39) @lasted(1m21s)
            ✔ Implement random mode @started(21-06-01 18:54) @done(21-06-02 07:45) @lasted(12h51m41s)
            ✔ Implement clustered mode @started(21-06-01 18:54) @done(21-06-02 07:45) @lasted(12h51m42s)
        ✔ Apply mods to init() and reset() @started(21-06-02 07:45) @done(21-06-02 08:30) @lasted(45m23s)
        ☐ Smoke test @started(21-06-02 08:30)
    
MEDA.Experiments:
    ☐ Pilot testing
        ☐ Test model after applying all randomizations
        ☐ Try profiling MEDA module and fix inefficient code

MEDA.META:




